{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Machine Learning & Statistical Modeling\n",
    "\n",
    "## Objectives:\n",
    "1. For each zipcode, fit a linear regression model that predicts total claims\n",
    "2. Develop ML model that predicts optimal premium values\n",
    "3. Report on important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data for machine learning...\n",
      "Dataset shape: (618176, 52)\n",
      "Rows: 618,176\n",
      "Columns: 52\n",
      "\n",
      "Target variables:\n",
      "TotalPremium mean: R100.20\n",
      "TotalClaims mean: R100.41\n",
      "SumInsured mean: R609826.86\n",
      "\n",
      "Unique zipcodes: 858\n",
      "Zipcodes with at least 50 policies: 746\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load and prepare data for machine learning\n",
    "print(\"Loading and preparing data for machine learning...\")\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('../data/raw/insurance_data.txt', delimiter='|', low_memory=False)\n",
    "\n",
    "# Convert key columns to numeric\n",
    "df['TotalPremium'] = pd.to_numeric(df['TotalPremium'], errors='coerce')\n",
    "df['TotalClaims'] = pd.to_numeric(df['TotalClaims'], errors='coerce')\n",
    "df['SumInsured'] = pd.to_numeric(df['SumInsured'], errors='coerce')\n",
    "\n",
    "# Filter out zero premiums and create working dataset\n",
    "df_ml = df[df['TotalPremium'] > 0].copy()\n",
    "\n",
    "# Basic info\n",
    "print(f\"Dataset shape: {df_ml.shape}\")\n",
    "print(f\"Rows: {df_ml.shape[0]:,}\")\n",
    "print(f\"Columns: {df_ml.shape[1]}\")\n",
    "print()\n",
    "\n",
    "# Check target variables\n",
    "print(\"Target variables:\")\n",
    "print(f\"TotalPremium mean: R{df_ml['TotalPremium'].mean():.2f}\")\n",
    "print(f\"TotalClaims mean: R{df_ml['TotalClaims'].mean():.2f}\")\n",
    "print(f\"SumInsured mean: R{df_ml['SumInsured'].mean():.2f}\")\n",
    "print()\n",
    "\n",
    "# Check unique zipcodes\n",
    "if 'PostalCode' in df_ml.columns:\n",
    "    print(f\"Unique zipcodes: {df_ml['PostalCode'].nunique():,}\")\n",
    "    print(f\"Zipcodes with at least 50 policies: {(df_ml['PostalCode'].value_counts() >= 50).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PREPARING FEATURES FOR MACHINE LEARNING\n",
      "============================================================\n",
      "Available features: 21\n",
      "Features available for modeling:\n",
      "   1. SumInsured\n",
      "   2. ExcessSelected\n",
      "   3. CoverType\n",
      "   4. Product\n",
      "   5. TermFrequency\n",
      "   6. Province\n",
      "   7. PostalCode\n",
      "   8. Gender\n",
      "   9. MaritalStatus\n",
      "  10. AccountType\n",
      "  11. VehicleType\n",
      "  12. make\n",
      "  13. Model\n",
      "  14. RegistrationYear\n",
      "  15. Cylinders\n",
      "  16. cubiccapacity\n",
      "  17. bodytype\n",
      "  18. NumberOfDoors\n",
      "  19. AlarmImmobiliser\n",
      "  20. TrackingDevice\n",
      "  21. NewVehicle\n",
      "\n",
      "Missing values in selected features:\n",
      "  Gender                       4,621 (0.7%)\n",
      "  MaritalStatus                5,071 (0.8%)\n",
      "  AccountType                 30,734 (5.0%)\n",
      "  VehicleType                    218 (0.0%)\n",
      "  make                           218 (0.0%)\n",
      "  Model                          218 (0.0%)\n",
      "  Cylinders                      218 (0.0%)\n",
      "  cubiccapacity                  218 (0.0%)\n",
      "  bodytype                       218 (0.0%)\n",
      "  NumberOfDoors                  218 (0.0%)\n",
      "  NewVehicle                  60,634 (9.8%)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Prepare features for modeling\n",
    "print(\"=\" * 60)\n",
    "print(\"PREPARING FEATURES FOR MACHINE LEARNING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Select features for modeling\n",
    "# Based on domain knowledge and data availability\n",
    "potential_features = [\n",
    "    # Policy/Client features\n",
    "    'SumInsured',\n",
    "    'ExcessSelected',  # Might be categorical\n",
    "    'CoverType',\n",
    "    'Product',\n",
    "    'TermFrequency',\n",
    "    \n",
    "    # Client demographics\n",
    "    'Province',\n",
    "    'PostalCode',\n",
    "    'Gender',\n",
    "    'MaritalStatus',\n",
    "    'AccountType',\n",
    "    \n",
    "    # Vehicle features\n",
    "    'VehicleType',\n",
    "    'make',\n",
    "    'Model',\n",
    "    'RegistrationYear',\n",
    "    'Cylinders',\n",
    "    'cubiccapacity',\n",
    "    'bodytype',\n",
    "    'NumberOfDoors',\n",
    "    \n",
    "    # Risk features\n",
    "    'AlarmImmobiliser',\n",
    "    'TrackingDevice',\n",
    "    'NewVehicle',\n",
    "]\n",
    "\n",
    "# Check which features are available\n",
    "available_features = [f for f in potential_features if f in df_ml.columns]\n",
    "print(f\"Available features: {len(available_features)}\")\n",
    "print(\"Features available for modeling:\")\n",
    "for i, feat in enumerate(available_features, 1):\n",
    "    print(f\"  {i:2d}. {feat}\")\n",
    "print()\n",
    "\n",
    "# Check for missing values in these features\n",
    "print(\"Missing values in selected features:\")\n",
    "missing_counts = {}\n",
    "for feat in available_features:\n",
    "    missing = df_ml[feat].isnull().sum()\n",
    "    if missing > 0:\n",
    "        missing_counts[feat] = missing\n",
    "        print(f\"  {feat:25} {missing:8,} ({missing/len(df_ml)*100:.1f}%)\")\n",
    "\n",
    "if not missing_counts:\n",
    "    print(\"  No missing values in selected features!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CREATING FINAL MODELING DATASET\n",
      "============================================================\n",
      "Selected features: ['SumInsured', 'Province', 'VehicleType', 'CoverType', 'TermFrequency', 'AlarmImmobiliser', 'PostalCode']\n",
      "Target 1: TotalClaims (for claims prediction)\n",
      "Target 2: TotalPremium (for premium prediction)\n",
      "\n",
      "Data types of selected features:\n",
      "  SumInsured           float64    Unique: N/A\n",
      "  Province             object     Unique: 9\n",
      "  VehicleType          object     Unique: 5\n",
      "  CoverType            object     Unique: 21\n",
      "  TermFrequency        object     Unique: 2\n",
      "  AlarmImmobiliser     object     Unique: 2\n",
      "  PostalCode           int64      Unique: N/A\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Create final modeling dataset\n",
    "print(\"=\" * 60)\n",
    "print(\"CREATING FINAL MODELING DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a copy for modeling\n",
    "df_model = df_ml.copy()\n",
    "\n",
    "# 1. Select features (start with a manageable set)\n",
    "selected_features = [\n",
    "    'SumInsured',           # Important: higher sum insured = higher risk\n",
    "    'Province',             # Geographic risk\n",
    "    'VehicleType',          # Type of vehicle\n",
    "    'CoverType',            # Type of coverage\n",
    "    'TermFrequency',        # Payment frequency\n",
    "    'AlarmImmobiliser',     # Security feature\n",
    "]\n",
    "\n",
    "# Also include zipcode for grouping\n",
    "if 'PostalCode' in df_model.columns:\n",
    "    selected_features.append('PostalCode')\n",
    "\n",
    "# Target variables\n",
    "target_claims = 'TotalClaims'\n",
    "target_premium = 'TotalPremium'\n",
    "\n",
    "print(f\"Selected features: {selected_features}\")\n",
    "print(f\"Target 1: {target_claims} (for claims prediction)\")\n",
    "print(f\"Target 2: {target_premium} (for premium prediction)\")\n",
    "print()\n",
    "\n",
    "# Check data types\n",
    "print(\"Data types of selected features:\")\n",
    "for feat in selected_features:\n",
    "    if feat in df_model.columns:\n",
    "        dtype = df_model[feat].dtype\n",
    "        unique = df_model[feat].nunique() if dtype == 'object' else 'N/A'\n",
    "        print(f\"  {feat:20} {str(dtype):10} Unique: {unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "OBJECTIVE 1: LINEAR REGRESSION FOR TOTAL CLAIMS\n",
      "============================================================\n",
      "Starting with numerical features only...\n",
      "\n",
      "1. Correlation analysis:\n",
      "   SumInsured           Correlation with Claims: -0.0063\n",
      "\n",
      "2. Data split:\n",
      "   Training samples: 494,540\n",
      "   Test samples: 123,636\n",
      "\n",
      "3. Model Performance:\n",
      "   Mean Squared Error (MSE): 6,522,068.32\n",
      "   Root Mean Squared Error (RMSE): 2,553.83\n",
      "   Mean Absolute Error (MAE): 193.70\n",
      "   R-squared (R²): 0.0001\n",
      "\n",
      "4. Model Coefficients:\n",
      "   SumInsured: -0.000012\n",
      "   Intercept: 109.51\n",
      "\n",
      "5. Interpretation:\n",
      "   • R² = 0.0001 means the model explains 0.0% of variance in claims\n",
      "   • RMSE = R2553.83 means average prediction error is R2553.83\n",
      "   • WARNING: Very low R². Need more/better features.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Simple Linear Regression for TotalClaims\n",
    "print(\"=\" * 60)\n",
    "print(\"OBJECTIVE 1: LINEAR REGRESSION FOR TOTAL CLAIMS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# For linear regression, we need to handle categorical variables\n",
    "# Let's start with just numerical features for simplicity\n",
    "print(\"Starting with numerical features only...\")\n",
    "\n",
    "# Select numerical features for initial model\n",
    "numerical_features = ['SumInsured']  # Start simple\n",
    "\n",
    "# Check correlation with TotalClaims\n",
    "print(\"\\n1. Correlation analysis:\")\n",
    "for feat in numerical_features:\n",
    "    if feat in df_model.columns:\n",
    "        corr = df_model[feat].corr(df_model['TotalClaims'])\n",
    "        print(f\"   {feat:20} Correlation with Claims: {corr:.4f}\")\n",
    "\n",
    "# Prepare data\n",
    "X = df_model[numerical_features].fillna(df_model[numerical_features].mean())\n",
    "y = df_model['TotalClaims']\n",
    "\n",
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\n2. Data split:\")\n",
    "print(f\"   Training samples: {X_train.shape[0]:,}\")\n",
    "print(f\"   Test samples: {X_test.shape[0]:,}\")\n",
    "\n",
    "# Train linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n3. Model Performance:\")\n",
    "print(f\"   Mean Squared Error (MSE): {mse:,.2f}\")\n",
    "print(f\"   Root Mean Squared Error (RMSE): {rmse:,.2f}\")\n",
    "print(f\"   Mean Absolute Error (MAE): {mae:,.2f}\")\n",
    "print(f\"   R-squared (R²): {r2:.4f}\")\n",
    "\n",
    "print(f\"\\n4. Model Coefficients:\")\n",
    "for i, feat in enumerate(numerical_features):\n",
    "    print(f\"   {feat}: {lr_model.coef_[i]:.6f}\")\n",
    "print(f\"   Intercept: {lr_model.intercept_:.2f}\")\n",
    "\n",
    "print(f\"\\n5. Interpretation:\")\n",
    "print(f\"   • R² = {r2:.4f} means the model explains {r2*100:.1f}% of variance in claims\")\n",
    "print(f\"   • RMSE = R{rmse:.2f} means average prediction error is R{rmse:.2f}\")\n",
    "if r2 < 0.1:\n",
    "    print(f\"   • WARNING: Very low R². Need more/better features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ADDING CATEGORICAL FEATURES WITH ONE-HOT ENCODING\n",
      "============================================================\n",
      "Features for enhanced model: ['SumInsured', 'Province', 'VehicleType', 'CoverType']\n",
      "\n",
      "Training enhanced linear regression model...\n",
      "\n",
      "Enhanced Model Performance:\n",
      "   R-squared (R²): 0.0059 (explains 0.6% of variance)\n",
      "   RMSE: R2546.34\n",
      "   MAE: R209.93\n",
      "\n",
      "Comparison with simple model:\n",
      "   Simple model R²: 0.0059\n",
      "   Enhanced model R²: 0.0059\n",
      "   Improvement: 0.0000\n",
      "\n",
      "Top 10 most important features (by absolute coefficient):\n",
      "   CoverType_Standalone passenger liability Coef: -8900.04\n",
      "   CoverType_Passenger Liability            Coef: -8895.80\n",
      "   CoverType_Third Party Only               Coef: -1828.63\n",
      "   CoverType_Own Damage                     Coef:  1642.52\n",
      "   VehicleType_nan                          Coef:  1460.32\n",
      "   CoverType_Income Protector               Coef:  1219.76\n",
      "   CoverType_Trailer                        Coef:  1196.95\n",
      "   CoverType_Windscreen                     Coef:  1188.67\n",
      "   CoverType_Roadside Assistance            Coef:  1166.06\n",
      "   CoverType_Cash Takings                   Coef:  1163.68\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Adding Categorical Features with One-Hot Encoding\n",
    "print(\"=\" * 60)\n",
    "print(\"ADDING CATEGORICAL FEATURES WITH ONE-HOT ENCODING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Select categorical features to add\n",
    "categorical_features = ['Province', 'VehicleType', 'CoverType']\n",
    "\n",
    "# Create new feature set\n",
    "all_features = numerical_features + categorical_features\n",
    "\n",
    "print(f\"Features for enhanced model: {all_features}\")\n",
    "print()\n",
    "\n",
    "# Prepare data with one-hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_cols = numerical_features\n",
    "categorical_cols = categorical_features\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Create pipeline with preprocessing and linear regression\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Split data\n",
    "X = df_model[all_features]\n",
    "y = df_model['TotalClaims']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "print(\"Training enhanced linear regression model...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nEnhanced Model Performance:\")\n",
    "print(f\"   R-squared (R²): {r2:.4f} (explains {r2*100:.1f}% of variance)\")\n",
    "print(f\"   RMSE: R{rmse:.2f}\")\n",
    "print(f\"   MAE: R{mae:.2f}\")\n",
    "\n",
    "# Compare with simple model\n",
    "print(f\"\\nComparison with simple model:\")\n",
    "print(f\"   Simple model R²: {r2:.4f}\")\n",
    "print(f\"   Enhanced model R²: {r2:.4f}\")\n",
    "print(f\"   Improvement: {(r2 - r2):.4f}\")\n",
    "\n",
    "# Get feature importance (for linear model, coefficients)\n",
    "try:\n",
    "    # Extract feature names after one-hot encoding\n",
    "    cat_encoder = pipeline.named_steps['preprocessor'].named_transformers_['cat']\n",
    "    cat_feature_names = cat_encoder.get_feature_names_out(categorical_cols)\n",
    "    all_feature_names = numerical_cols + list(cat_feature_names)\n",
    "    \n",
    "    # Get coefficients\n",
    "    coefficients = pipeline.named_steps['regressor'].coef_\n",
    "    \n",
    "    print(f\"\\nTop 10 most important features (by absolute coefficient):\")\n",
    "    feat_importance = pd.DataFrame({\n",
    "        'Feature': all_feature_names,\n",
    "        'Coefficient': coefficients\n",
    "    })\n",
    "    feat_importance['Abs_Coefficient'] = np.abs(feat_importance['Coefficient'])\n",
    "    feat_importance = feat_importance.sort_values('Abs_Coefficient', ascending=False).head(10)\n",
    "    \n",
    "    for _, row in feat_importance.iterrows():\n",
    "        print(f\"   {row['Feature'][:40]:40} Coef: {row['Coefficient']:8.2f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Could not extract feature importance: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
